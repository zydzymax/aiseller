import os
import json
import logging
import asyncio
from collections import defaultdict
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, MessageHandler, ContextTypes, filters, PicklePersistence
from llm_logic import generate_response
from claude_emotion import analyze_emotion, humanize_reply

# –ó–∞–≥—Ä—É–∑–∫–∞ .env
load_dotenv(dotenv_path=os.path.expanduser("~/ai_seller/project/.env"))
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

# –õ–æ–≥–≥–µ—Ä
logging.basicConfig(format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis)
user_states = defaultdict(dict)


def load_personality() -> dict:
    path = os.path.expanduser("~/ai_seller/project/python-core/config/personality_templates.json")
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)["telegram_sales_bot"]


def build_system_prompt(data: dict) -> str:
    parts = [
        data["role"],
        data["company"],
        data["product"],
        "–¢–æ–Ω –æ–±—â–µ–Ω–∏—è: " + data["tone"],
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç: " + data["behavior_context"],
        "–ü—Ä–∞–≤–∏–ª–∞: " + " ".join(data["rules"]),
        "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ: " + " ".join(data["CRITICAL_INSTRUCTIONS"]["–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û"])
    ]
    return "\n".join(parts)


PERSONA = load_personality()
KEY_QUESTIONS = PERSONA["key_questions"]
SYSTEM_PROMPT = build_system_prompt(PERSONA)


def get_user_state(user_id: int) -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id not in user_states:
        user_states[user_id] = {
            "dialog_started": False,
            "lead_info": {},
            "question_index": 0,
            "messages_count": 0,
            "conversation_history": []
        }
    return user_states[user_id]


def update_user_state(user_id: int, **kwargs) -> None:
    """–û–±–Ω–æ–≤–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    state = get_user_state(user_id)
    state.update(kwargs)
    user_states[user_id] = state


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_input = update.message.text.strip()
    user_id = update.effective_user.id
    logger.info(f"üì© [{user_id}] {user_input}")

    # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    state = get_user_state(user_id)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
    state["conversation_history"].append({"role": "user", "content": user_input})
    state["messages_count"] += 1

    # –ü–ï–†–í–û–ï –°–û–û–ë–©–ï–ù–ò–ï - —Ç–æ–ª—å–∫–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
    if not state["dialog_started"]:
        state["dialog_started"] = True
        update_user_state(user_id, **state)

        welcome = (
            "–ü—Ä–∏–≤–µ—Ç! –ú–µ–Ω—è –∑–æ–≤—É—Ç –õ–µ–Ω–∞, —è –º–µ–Ω–µ–¥–∂–µ—Ä —à–≤–µ–π–Ω–æ–π —Ñ–∞–±—Ä–∏–∫–∏ SoVAni üòä\n"
            "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ—à–∏—Ç—å ‚Äî –ø–æ–¥—Å–∫–∞–∂—É, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å."
        )
        styled_welcome = humanize_reply(welcome, SYSTEM_PROMPT, user_input)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
        state["conversation_history"].append({"role": "assistant", "content": styled_welcome})
        update_user_state(user_id, **state)
        
        await update.message.reply_text(styled_welcome)
        return

    # –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê –î–ò–ê–õ–û–ì–ê
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è ChatGPT
    conversation_context = ""
    if state["conversation_history"]:
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        recent_history = state["conversation_history"][-4:]
        for msg in recent_history:
            role = "–ö–ª–∏–µ–Ω—Ç" if msg["role"] == "user" else "–ú–µ–Ω–µ–¥–∂–µ—Ä"
            conversation_context += f"{role}: {msg['content']}\n"
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç ChatGPT
    raw_response = generate_response(
        user_input, 
        system_prompt=SYSTEM_PROMPT,
        conversation_history=conversation_context
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–¥–∞—Ç—å –∫–ª—é—á–µ–≤–æ–π –≤–æ–ø—Ä–æ—Å
    current_question_index = state["question_index"]
    needs_key_question = should_ask_key_question(user_input, state["lead_info"], current_question_index)
    
    if needs_key_question and current_question_index < len(KEY_QUESTIONS):
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤–æ–π –≤–æ–ø—Ä–æ—Å –∫ –æ—Ç–≤–µ—Ç—É
        key_question = KEY_QUESTIONS[current_question_index]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –ª–∏ —É–∂–µ –∫–ª–∏–µ–Ω—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –≤ —Å–≤–æ–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
        if not answer_covers_question(user_input, key_question):
            combined_response = f"{raw_response}\n\n{key_question}"
        else:
            # –ö–ª–∏–µ–Ω—Ç —É–∂–µ –æ—Ç–≤–µ—Ç–∏–ª, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç
            state["lead_info"][key_question] = user_input
            combined_response = raw_response
        
        state["question_index"] += 1
    else:
        combined_response = raw_response
    
    # –°—Ç–∏–ª–∏–∑—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ Claude
    styled_response = humanize_reply(combined_response, SYSTEM_PROMPT, user_input)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
    state["conversation_history"].append({"role": "assistant", "content": styled_response})
    update_user_state(user_id, **state)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
    await update.message.reply_text(styled_response)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–±—Ä–∞–ª–∏ –ª–∏ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    if len(state["lead_info"]) >= len(KEY_QUESTIONS):
        logger.info(f"‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {state['lead_info']}")
        await notify_managers(update, state["lead_info"])


def should_ask_key_question(user_message: str, lead_info: dict, question_index: int) -> bool:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–¥–∞—Ç—å –∫–ª—é—á–µ–≤–æ–π –≤–æ–ø—Ä–æ—Å"""
    # –ï—Å–ª–∏ –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã —É–∂–µ –∑–∞–¥–∞–Ω—ã
    if question_index >= len(KEY_QUESTIONS):
        return False
    
    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —Ç–æ–ª—å–∫–æ –ø–æ–∑–¥–æ—Ä–æ–≤–∞–ª—Å—è - –Ω–µ –∑–∞–¥–∞–µ–º —Å—Ä–∞–∑—É –≤–æ–ø—Ä–æ—Å
    greetings = ["–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "hi", "hello"]
    if any(greeting in user_message.lower() for greeting in greetings) and len(user_message.split()) <= 2:
        return False
    
    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–∂–µ –¥–∞–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é - –Ω–µ –¥—É–±–ª–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å
    current_question = KEY_QUESTIONS[question_index]
    if answer_covers_question(user_message, current_question):
        return False
    
    # –í –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö –∑–∞–¥–∞–µ–º –≤–æ–ø—Ä–æ—Å, –Ω–æ –Ω–µ —á–∞—â–µ —á–µ–º –∫–∞–∂–¥—ã–µ 2 —Å–æ–æ–±—â–µ–Ω–∏—è
    return True


def answer_covers_question(user_message: str, question: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–≤–µ—á–∞–µ—Ç –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å"""
    user_lower = user_message.lower()
    question_lower = question.lower()
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
    coverage_patterns = {
        "–∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç": ["—Ñ—É—Ç–±–æ–ª–∫", "–ø–ª–∞—Ç—å–µ", "–±—Ä—é–∫–∏", "—é–±–∫", "–±–ª—É–∑–∫", "–ø–∏–∂–∞–º", "–∫–æ—Å—Ç—é–º", "—Å–≤–∏—Ç–µ—Ä"],
        "—Ç–∏—Ä–∞–∂": ["—à—Ç—É–∫", "–µ–¥–∏–Ω–∏—Ü", "—Ç—ã—Å—è—á", "—Å–æ—Ç–µ–Ω", "–º–Ω–æ–≥–æ", "–º–∞–ª–æ", "—Ç–∏—Ä–∞–∂"],
        "–±—é–¥–∂–µ—Ç": ["—Ä—É–±–ª", "—Ç—ã—Å—è—á", "–±—é–¥–∂–µ—Ç", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Ü–µ–Ω–∞", "–¥–æ—Ä–æ–≥–æ", "–¥–µ—à–µ–≤–æ"],
        "—Å—Ä–æ–∫–∏": ["–Ω–µ–¥–µ–ª", "–º–µ—Å—è—Ü", "—Å—Ä–æ—á–Ω–æ", "–±—ã—Å—Ç—Ä–æ", "–∫–æ–≥–¥–∞", "—Å—Ä–æ–∫–∏", "–≤—Ä–µ–º—è"],
    }
    
    for topic, keywords in coverage_patterns.items():
        if topic in question_lower:
            if any(keyword in user_lower for keyword in keywords):
                return True
    
    return False


async def notify_managers(update: Update, lead_info: dict) -> None:
    """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –æ –Ω–æ–≤–æ–º –ª–∏–¥–µ"""
    try:
        user = update.effective_user
        message = (
            f"üßµ –ù–æ–≤—ã–π –ª–∏–¥ –≥–æ—Ç–æ–≤ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ!\n"
            f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: @{user.username or user.first_name} (ID: {user.id})\n"
            f"üìå –°–æ–±—Ä–∞–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n\n"
        )
        
        for question, answer in lead_info.items():
            message += f"‚Ä¢ {question}\n  ‚ûú {answer}\n\n"

        logger.info(f"üì® –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º:\n{message}")
        
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É –≤ CRM, email, Telegram-–≥—Ä—É–ø–ø—É –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ notify_managers: {e}")


async def main() -> None:
    if not TELEGRAM_TOKEN:
        logger.error("‚ùå TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏")
        return
    
    # –°–æ–∑–¥–∞–µ–º persistence –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–π
    persistence_file = os.path.expanduser("~/ai_seller/project/bot_data.pkl")
    persistence = PicklePersistence(filepath=persistence_file)
    
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).persistence(persistence).build()
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    logger.info("üéØ –ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–π...")
    await app.run_polling()


if __name__ == "__main__":
    import nest_asyncio
    nest_asyncio.apply()
    logger.info("üîÑ –ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞...")
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("‚è≥ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")